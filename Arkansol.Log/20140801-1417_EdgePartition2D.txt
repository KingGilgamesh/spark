Warning: SPARK_MEM is deprecated, please use a more specific config option
(e.g., spark.executor.memory or SPARK_DRIVER_MEMORY).
======================================
|             PageRank               |
======================================
14/08/01 14:17:49 INFO SparkConf: Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
14/08/01 14:17:49 WARN SparkConf: 
SPARK_JAVA_OPTS was detected (set to '-Dspark.executor.memory=60g').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
14/08/01 14:17:49 WARN SparkConf: Setting 'spark.executor.extraJavaOptions' to '-Dspark.executor.memory=60g' as a work-around.
14/08/01 14:17:49 WARN SparkConf: Setting 'spark.driver.extraJavaOptions' to '-Dspark.executor.memory=60g' as a work-around.
14/08/01 14:17:49 INFO SecurityManager: Changing view acls to: xiaodi
14/08/01 14:17:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xiaodi)
14/08/01 14:17:50 INFO Slf4jLogger: Slf4jLogger started
14/08/01 14:17:50 INFO Remoting: Starting remoting
14/08/01 14:17:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@brick0.ipads-lab.se.sjtu.edu.cn:45875]
14/08/01 14:17:50 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@brick0.ipads-lab.se.sjtu.edu.cn:45875]
14/08/01 14:17:50 INFO SparkEnv: Registering MapOutputTracker
14/08/01 14:17:50 INFO SparkEnv: Registering BlockManagerMaster
14/08/01 14:17:50 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140801141750-1c1e
14/08/01 14:17:50 INFO ConnectionManager: Bound socket to port 53632 with id = ConnectionManagerId(brick0.ipads-lab.se.sjtu.edu.cn,53632)
14/08/01 14:17:50 INFO MemoryStore: MemoryStore started with capacity 34.5 GB
14/08/01 14:17:50 INFO BlockManagerMaster: Trying to register BlockManager
14/08/01 14:17:50 INFO BlockManagerInfo: Registering block manager brick0.ipads-lab.se.sjtu.edu.cn:53632 with 34.5 GB RAM
14/08/01 14:17:50 INFO BlockManagerMaster: Registered BlockManager
14/08/01 14:17:50 INFO HttpServer: Starting HTTP Server
14/08/01 14:17:50 INFO HttpBroadcast: Broadcast server started at http://192.168.12.124:59048
14/08/01 14:17:50 INFO HttpFileServer: HTTP File server directory is /tmp/spark-f13830dc-8d3a-49e8-a99f-78a40d6fa737
14/08/01 14:17:50 INFO HttpServer: Starting HTTP Server
14/08/01 14:17:51 WARN JettyUtils: Failed to create UI on port 4040. Trying again on port 4041. - Failure(java.net.BindException: Address already in use)
14/08/01 14:17:51 WARN JettyUtils: Failed to create UI on port 4041. Trying again on port 4042. - Failure(java.net.BindException: Address already in use)
14/08/01 14:17:51 INFO SparkUI: Started SparkUI at http://brick0.ipads-lab.se.sjtu.edu.cn:4042
14/08/01 14:17:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/01 14:17:51 INFO EventLoggingListener: Logging events to /tmp/spark-events/pagerank(-data-sdd1-xiaodi-data-in-1.8-10m_aa)-some(edgepartition2d)-1406873871884
14/08/01 14:17:52 INFO SparkContext: Added JAR file:/data/sdd1/xiaodi/spark/examples/target/scala-2.10/spark-examples-1.1.0-SNAPSHOT-hadoop1.0.4.jar at http://192.168.12.124:38828/jars/spark-examples-1.1.0-SNAPSHOT-hadoop1.0.4.jar with timestamp 1406873872362
14/08/01 14:17:52 INFO AppClient$ClientActor: Connecting to master spark://brick0:7077...
14/08/01 14:17:52 INFO MemoryStore: ensureFreeSpace(42201) called with curMem=0, maxMem=37044092928
14/08/01 14:17:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 41.2 KB, free 34.5 GB)
14/08/01 14:17:52 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20140801141752-0001
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor added: app-20140801141752-0001/0 on worker-20140801141635-brick2.ipads-lab.se.sjtu.edu.cn-37368 (brick2.ipads-lab.se.sjtu.edu.cn:37368) with 24 cores
14/08/01 14:17:52 INFO SparkDeploySchedulerBackend: Granted executor ID app-20140801141752-0001/0 on hostPort brick2.ipads-lab.se.sjtu.edu.cn:37368 with 24 cores, 60.0 GB RAM
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor added: app-20140801141752-0001/1 on worker-20140801141635-brick5.ipads-lab.se.sjtu.edu.cn-52922 (brick5.ipads-lab.se.sjtu.edu.cn:52922) with 24 cores
14/08/01 14:17:52 INFO SparkDeploySchedulerBackend: Granted executor ID app-20140801141752-0001/1 on hostPort brick5.ipads-lab.se.sjtu.edu.cn:52922 with 24 cores, 60.0 GB RAM
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor added: app-20140801141752-0001/2 on worker-20140801141634-brick0.ipads-lab.se.sjtu.edu.cn-33607 (brick0.ipads-lab.se.sjtu.edu.cn:33607) with 24 cores
14/08/01 14:17:52 INFO SparkDeploySchedulerBackend: Granted executor ID app-20140801141752-0001/2 on hostPort brick0.ipads-lab.se.sjtu.edu.cn:33607 with 24 cores, 60.0 GB RAM
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor added: app-20140801141752-0001/3 on worker-20140801141636-brick4.ipads-lab.se.sjtu.edu.cn-40434 (brick4.ipads-lab.se.sjtu.edu.cn:40434) with 24 cores
14/08/01 14:17:52 INFO SparkDeploySchedulerBackend: Granted executor ID app-20140801141752-0001/3 on hostPort brick4.ipads-lab.se.sjtu.edu.cn:40434 with 24 cores, 60.0 GB RAM
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor added: app-20140801141752-0001/4 on worker-20140801141635-brick1.ipads-lab.se.sjtu.edu.cn-46509 (brick1.ipads-lab.se.sjtu.edu.cn:46509) with 24 cores
14/08/01 14:17:52 INFO SparkDeploySchedulerBackend: Granted executor ID app-20140801141752-0001/4 on hostPort brick1.ipads-lab.se.sjtu.edu.cn:46509 with 24 cores, 60.0 GB RAM
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor added: app-20140801141752-0001/5 on worker-20140801141635-brick3.ipads-lab.se.sjtu.edu.cn-38437 (brick3.ipads-lab.se.sjtu.edu.cn:38437) with 24 cores
14/08/01 14:17:52 INFO SparkDeploySchedulerBackend: Granted executor ID app-20140801141752-0001/5 on hostPort brick3.ipads-lab.se.sjtu.edu.cn:38437 with 24 cores, 60.0 GB RAM
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor updated: app-20140801141752-0001/0 is now RUNNING
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor updated: app-20140801141752-0001/5 is now RUNNING
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor updated: app-20140801141752-0001/1 is now RUNNING
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor updated: app-20140801141752-0001/2 is now RUNNING
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor updated: app-20140801141752-0001/3 is now RUNNING
14/08/01 14:17:52 INFO AppClient$ClientActor: Executor updated: app-20140801141752-0001/4 is now RUNNING
14/08/01 14:17:53 WARN LoadSnappy: Snappy native library not loaded
14/08/01 14:17:53 INFO FileInputFormat: Total input paths to process : 1
14/08/01 14:17:53 INFO SparkContext: Starting job: count at GraphLoader.scala:87
14/08/01 14:17:53 INFO DAGScheduler: Got job 0 (count at GraphLoader.scala:87) with 144 output partitions (allowLocal=false)
14/08/01 14:17:53 INFO DAGScheduler: Final stage: Stage 0(count at GraphLoader.scala:87)
14/08/01 14:17:53 INFO DAGScheduler: Parents of final stage: List()
14/08/01 14:17:53 INFO DAGScheduler: Missing parents: List()
14/08/01 14:17:53 INFO DAGScheduler: Submitting Stage 0 (GraphLoader.edgeListFile - edges (/data/sdd1/xiaodi/data/in-1.8-10m_aa) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68), which has no missing parents
14/08/01 14:17:53 INFO DAGScheduler: Submitting 144 missing tasks from Stage 0 (GraphLoader.edgeListFile - edges (/data/sdd1/xiaodi/data/in-1.8-10m_aa) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68)
14/08/01 14:17:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 144 tasks
14/08/01 14:17:56 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@brick0.ipads-lab.se.sjtu.edu.cn:48331/user/Executor#656362996] with ID 2
14/08/01 14:17:56 INFO TaskSetManager: Re-computing pending task lists.
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:0 as 2331 bytes in 3 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:1 as TID 1 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:1 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:2 as TID 2 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:2 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:3 as TID 3 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:3 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:4 as TID 4 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:4 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:5 as TID 5 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:5 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:6 as TID 6 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:6 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:7 as TID 7 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:7 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:8 as TID 8 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:8 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:9 as TID 9 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:9 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:10 as TID 10 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:10 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:11 as TID 11 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:11 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:12 as TID 12 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:12 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:13 as TID 13 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:13 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:14 as TID 14 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:14 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:15 as TID 15 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:15 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:16 as TID 16 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:16 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:17 as TID 17 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:17 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:18 as TID 18 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:18 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:19 as TID 19 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:19 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:20 as TID 20 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:20 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:21 as TID 21 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:21 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:22 as TID 22 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:22 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:23 as TID 23 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:23 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@brick1.ipads-lab.se.sjtu.edu.cn:60318/user/Executor#-1756054959] with ID 4
14/08/01 14:17:56 INFO TaskSetManager: Re-computing pending task lists.
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:24 as TID 24 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:24 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:25 as TID 25 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:25 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:26 as TID 26 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:26 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:27 as TID 27 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:27 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:28 as TID 28 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:28 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:29 as TID 29 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:29 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:30 as TID 30 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:30 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:31 as TID 31 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:31 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:32 as TID 32 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:32 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:33 as TID 33 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:33 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:34 as TID 34 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:34 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:35 as TID 35 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:35 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:36 as TID 36 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:36 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:37 as TID 37 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:37 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:38 as TID 38 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:38 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:39 as TID 39 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:39 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:40 as TID 40 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:40 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:41 as TID 41 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:41 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:42 as TID 42 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:42 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:43 as TID 43 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:43 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:44 as TID 44 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:44 as 2331 bytes in 0 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:45 as TID 45 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:45 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:46 as TID 46 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:46 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO TaskSetManager: Starting task 0.0:47 as TID 47 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:56 INFO TaskSetManager: Serialized task 0.0:47 as 2331 bytes in 1 ms
14/08/01 14:17:56 INFO BlockManagerInfo: Registering block manager brick0.ipads-lab.se.sjtu.edu.cn:48046 with 34.5 GB RAM
14/08/01 14:17:57 INFO BlockManagerInfo: Registering block manager brick1.ipads-lab.se.sjtu.edu.cn:52115 with 34.5 GB RAM
14/08/01 14:17:57 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@brick4.ipads-lab.se.sjtu.edu.cn:34026/user/Executor#-177420732] with ID 3
14/08/01 14:17:57 INFO TaskSetManager: Re-computing pending task lists.
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:48 as TID 48 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:48 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:49 as TID 49 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:49 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:50 as TID 50 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:50 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:51 as TID 51 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:51 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:52 as TID 52 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:52 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:53 as TID 53 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:53 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:54 as TID 54 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:54 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:55 as TID 55 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:55 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:56 as TID 56 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:56 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:57 as TID 57 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:57 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:58 as TID 58 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:58 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:59 as TID 59 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:59 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:60 as TID 60 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:60 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:61 as TID 61 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:61 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:62 as TID 62 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:62 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:63 as TID 63 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:63 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:64 as TID 64 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:64 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:65 as TID 65 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:65 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:66 as TID 66 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:66 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:67 as TID 67 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:67 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:68 as TID 68 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:68 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:69 as TID 69 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:69 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:70 as TID 70 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:70 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:71 as TID 71 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:71 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@brick3.ipads-lab.se.sjtu.edu.cn:47506/user/Executor#-973464139] with ID 5
14/08/01 14:17:57 INFO TaskSetManager: Re-computing pending task lists.
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:72 as TID 72 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:72 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:73 as TID 73 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:73 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:74 as TID 74 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:74 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:75 as TID 75 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:75 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:76 as TID 76 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:76 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:77 as TID 77 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:77 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:78 as TID 78 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:78 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:79 as TID 79 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:79 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:80 as TID 80 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:80 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:81 as TID 81 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:81 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:82 as TID 82 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:82 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:83 as TID 83 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:83 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:84 as TID 84 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:84 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:85 as TID 85 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:85 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:86 as TID 86 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:86 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:87 as TID 87 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:87 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:88 as TID 88 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:88 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:89 as TID 89 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:89 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:90 as TID 90 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:90 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:91 as TID 91 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:91 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:92 as TID 92 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:92 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:93 as TID 93 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:93 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:94 as TID 94 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:94 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:95 as TID 95 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:95 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@brick2.ipads-lab.se.sjtu.edu.cn:52272/user/Executor#-302018071] with ID 0
14/08/01 14:17:57 INFO TaskSetManager: Re-computing pending task lists.
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:96 as TID 96 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:96 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:97 as TID 97 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:97 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:98 as TID 98 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:98 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:99 as TID 99 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:99 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:100 as TID 100 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:100 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:101 as TID 101 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:101 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:102 as TID 102 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:102 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:103 as TID 103 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:103 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:104 as TID 104 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:104 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:105 as TID 105 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:105 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:106 as TID 106 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:106 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:107 as TID 107 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:107 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:108 as TID 108 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:108 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:109 as TID 109 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:109 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:110 as TID 110 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:110 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:111 as TID 111 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:111 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:112 as TID 112 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:112 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:113 as TID 113 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:113 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:114 as TID 114 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:114 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:115 as TID 115 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:115 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:116 as TID 116 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:116 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:117 as TID 117 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:117 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:118 as TID 118 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:118 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:119 as TID 119 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:119 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@brick5.ipads-lab.se.sjtu.edu.cn:40104/user/Executor#-996602038] with ID 1
14/08/01 14:17:57 INFO TaskSetManager: Re-computing pending task lists.
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:120 as TID 120 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:120 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:121 as TID 121 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:121 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:122 as TID 122 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:122 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:123 as TID 123 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:123 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:124 as TID 124 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:124 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:125 as TID 125 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:125 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:126 as TID 126 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:126 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:127 as TID 127 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:127 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:128 as TID 128 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:128 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:129 as TID 129 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:129 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:130 as TID 130 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:130 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:131 as TID 131 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:131 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:132 as TID 132 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:132 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:133 as TID 133 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:133 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:134 as TID 134 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:134 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:135 as TID 135 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:135 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:136 as TID 136 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:136 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:137 as TID 137 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:137 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:138 as TID 138 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:138 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:139 as TID 139 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:139 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:140 as TID 140 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:140 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:141 as TID 141 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:141 as 2331 bytes in 0 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:142 as TID 142 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:142 as 2331 bytes in 1 ms
14/08/01 14:17:57 INFO TaskSetManager: Starting task 0.0:143 as TID 143 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:17:57 INFO TaskSetManager: Serialized task 0.0:143 as 2331 bytes in 0 ms
14/08/01 14:17:58 INFO BlockManagerInfo: Registering block manager brick4.ipads-lab.se.sjtu.edu.cn:55941 with 34.5 GB RAM
14/08/01 14:17:58 INFO BlockManagerInfo: Registering block manager brick2.ipads-lab.se.sjtu.edu.cn:37341 with 34.5 GB RAM
14/08/01 14:17:59 INFO BlockManagerInfo: Registering block manager brick5.ipads-lab.se.sjtu.edu.cn:39432 with 34.5 GB RAM
14/08/01 14:17:59 INFO BlockManagerInfo: Registering block manager brick3.ipads-lab.se.sjtu.edu.cn:33830 with 34.5 GB RAM
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_2 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_6 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_1 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_20 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_16 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_10 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_15 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_11 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_14 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_23 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_13 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_9 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_0 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 8.0 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_12 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_17 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_8 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_3 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 8.1 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_5 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 8.0 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_18 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_21 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_4 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 8.2 MB, free: 34.3 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_22 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_19 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:00 INFO BlockManagerInfo: Added rdd_3_7 in memory on brick0.ipads-lab.se.sjtu.edu.cn:48046 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 2 in 4585 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 1/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 2)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 17)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 17 in 4573 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 2/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 16)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 16 in 4591 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 3/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 6)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 6 in 4628 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 4/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 15)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 15 in 4622 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 5/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 10)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 10 in 4647 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 6/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 20)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 20 in 4641 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 7/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 14)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 14 in 4671 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 8/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 11)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 11 in 4692 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 9/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 13)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 13 in 4702 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 10/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 1)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 1 in 4745 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 11/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 0)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 0 in 4773 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 12/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 12)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 12 in 4749 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 13/144)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 23 in 4741 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 14/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 23)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 3)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 3 in 4797 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 15/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 9)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 9 in 4801 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 16/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 8)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 8 in 4817 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 17/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 7)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 7 in 4832 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 18/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 22)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 22 in 4814 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 19/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 21)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 21 in 4831 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 20/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 4)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 4 in 4881 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 21/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 19)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 19 in 4865 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 22/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 18)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 18 in 4881 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 23/144)
14/08/01 14:18:01 INFO DAGScheduler: Completed ResultTask(0, 5)
14/08/01 14:18:01 INFO TaskSetManager: Finished TID 5 in 4924 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 24/144)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_58 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 8.0 MB, free: 34.5 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_63 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_53 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_54 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 8.0 MB, free: 34.5 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_66 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_55 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_69 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_70 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_49 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_50 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_57 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_51 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_67 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_71 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_68 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_64 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_62 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_60 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 8.0 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_61 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 8.0 MB, free: 34.4 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_65 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_56 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_48 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_52 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:09 INFO BlockManagerInfo: Added rdd_3_59 in memory on brick4.ipads-lab.se.sjtu.edu.cn:55941 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 69)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 69 in 12053 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 25/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 51)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 51 in 12099 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 26/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 54)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 54 in 12110 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 27/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 52)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 52 in 12127 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 28/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 65)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 65 in 12115 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 29/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 71)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 71 in 12117 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 30/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 63)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 63 in 12144 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 31/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 68)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 68 in 12147 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 32/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 49)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 49 in 12195 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 33/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 55)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 55 in 12195 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 34/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 56)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 56 in 12204 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 35/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 64)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 64 in 12200 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 36/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 58)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 58 in 12226 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 37/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 70)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 70 in 12215 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 38/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 53)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 53 in 12259 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 39/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 50)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 50 in 12276 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 40/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 62)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 62 in 12264 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 41/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 48)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 48 in 12304 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 42/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 59)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 59 in 12292 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 43/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 61)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 61 in 12299 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 44/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 67)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 67 in 12299 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 45/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 60)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 60 in 12323 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 46/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 57)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 57 in 12341 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 47/144)
14/08/01 14:18:09 INFO DAGScheduler: Completed ResultTask(0, 66)
14/08/01 14:18:09 INFO TaskSetManager: Finished TID 66 in 12333 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 48/144)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_117 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_108 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_99 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_113 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_101 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_102 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_111 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_105 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_96 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_115 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_106 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_104 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_116 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_107 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_112 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_103 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_100 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_97 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_109 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_114 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_119 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_110 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_118 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_98 in memory on brick2.ipads-lab.se.sjtu.edu.cn:37341 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_77 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_94 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_75 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_91 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_85 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_92 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_82 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_93 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_90 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_87 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_84 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_83 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_88 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_79 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_81 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_76 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_95 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_89 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_86 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_73 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_78 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_80 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_72 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_74 in memory on brick3.ipads-lab.se.sjtu.edu.cn:33830 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 117)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 117 in 14786 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 49/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 108)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 108 in 14811 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 50/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 102)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 102 in 14831 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 51/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 116)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 116 in 14816 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 52/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 115)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 115 in 14826 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 53/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 104)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 104 in 14853 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 54/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 96)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 96 in 14876 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 55/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 114)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 114 in 14854 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 56/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 98)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 98 in 14887 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 57/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 99)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 99 in 14893 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 58/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 107)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 107 in 14888 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 59/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 119)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 119 in 14875 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 60/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 113)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 113 in 14893 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 61/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 103)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 103 in 14919 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 62/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 112)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 112 in 14912 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 63/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 101)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 101 in 14937 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 64/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 105)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 105 in 14938 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 65/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 111)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 111 in 14935 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 66/144)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_142 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_120 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_138 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_128 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 8.2 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_130 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_132 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_136 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 118)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 118 in 14931 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 67/144)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_123 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_127 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 8.2 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_129 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 8.1 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_131 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 8.0 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_141 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_133 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_135 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_143 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_140 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 100)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 100 in 14970 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 68/144)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_134 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_124 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_139 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_125 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 106)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 106 in 14968 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 69/144)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_122 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 8.0 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_137 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_121 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO BlockManagerInfo: Added rdd_3_126 in memory on brick5.ipads-lab.se.sjtu.edu.cn:39432 (size: 8.1 MB, free: 34.3 GB)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 97)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 97 in 14990 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 70/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 110)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 110 in 14976 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 71/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 109)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 109 in 14988 ms on brick2.ipads-lab.se.sjtu.edu.cn (progress: 72/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 85)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 85 in 15047 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 73/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 82)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 82 in 15059 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 74/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 78)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 78 in 15074 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 75/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 91)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 91 in 15060 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 76/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 75)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 75 in 15094 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 77/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 77)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 77 in 15099 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 78/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 86)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 86 in 15091 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 79/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 92)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 92 in 15088 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 80/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 94)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 94 in 15094 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 81/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 74)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 74 in 15136 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 82/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 95)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 95 in 15107 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 83/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 80)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 80 in 15138 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 84/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 73)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 73 in 15159 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 85/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 79)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 79 in 15155 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 86/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 72)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 72 in 15174 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 87/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 84)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 84 in 15159 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 88/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 87)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 87 in 15160 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 89/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 89)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 89 in 15163 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 90/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 83)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 83 in 15181 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 91/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 88)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 88 in 15179 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 92/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 90)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 90 in 15181 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 93/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 81)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 81 in 15204 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 94/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 76)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 76 in 15218 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 95/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 93)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 93 in 15196 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 96/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 128)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 128 in 15143 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 97/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 123)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 123 in 15157 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 98/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 142)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 142 in 15131 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 99/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 127)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 127 in 15161 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 100/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 138)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 138 in 15148 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 101/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 140)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 140 in 15151 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 102/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 130)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 130 in 15173 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 103/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 136)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 136 in 15168 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 104/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 131)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 131 in 15181 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 105/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 120)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 120 in 15207 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 106/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 137)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 137 in 15185 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 107/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 139)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 139 in 15185 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 108/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 126)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 126 in 15211 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 109/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 121)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 121 in 15227 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 110/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 124)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 124 in 15226 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 111/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 135)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 135 in 15214 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 112/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 141)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 141 in 15210 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 113/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 122)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 122 in 15247 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 114/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 143)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 143 in 15217 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 115/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 125)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 125 in 15253 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 116/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 132)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 132 in 15247 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 117/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 133)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 133 in 15250 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 118/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 134)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 134 in 15255 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 119/144)
14/08/01 14:18:12 INFO DAGScheduler: Completed ResultTask(0, 129)
14/08/01 14:18:12 INFO TaskSetManager: Finished TID 129 in 15268 ms on brick5.ipads-lab.se.sjtu.edu.cn (progress: 120/144)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_38 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_30 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_34 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_24 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_44 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_25 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.5 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_27 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_31 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_40 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_33 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_39 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_32 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_36 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_28 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_43 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_29 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_37 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_47 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_41 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.4 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_42 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_45 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_35 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_46 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:31 INFO BlockManagerInfo: Added rdd_3_26 in memory on brick1.ipads-lab.se.sjtu.edu.cn:52115 (size: 7.9 MB, free: 34.3 GB)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 28)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 28 in 35045 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 121/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 34)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 34 in 35040 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 122/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 36)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 36 in 35040 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 123/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 40)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 40 in 35038 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 124/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 33)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 33 in 35056 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 125/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 38)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 38 in 35052 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 126/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 44)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 44 in 35046 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 127/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 25)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 25 in 35086 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 128/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 27)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 27 in 35087 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 129/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 30)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 30 in 35087 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 130/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 29)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 29 in 35094 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 131/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 47)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 47 in 35064 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 132/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 24)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 24 in 35113 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 133/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 31)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 31 in 35104 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 134/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 43)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 43 in 35086 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 135/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 45)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 45 in 35088 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 136/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 35)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 35 in 35111 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 137/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 39)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 39 in 35107 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 138/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 32)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 32 in 35127 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 139/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 42)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 42 in 35112 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 140/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 37)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 37 in 35126 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 141/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 46)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 46 in 35114 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 142/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 26)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 26 in 35157 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 143/144)
14/08/01 14:18:31 INFO DAGScheduler: Completed ResultTask(0, 41)
14/08/01 14:18:31 INFO TaskSetManager: Finished TID 41 in 35133 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 144/144)
14/08/01 14:18:31 INFO DAGScheduler: Stage 0 (count at GraphLoader.scala:87) finished in 38.492 s
14/08/01 14:18:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
14/08/01 14:18:31 INFO SparkContext: Job finished: count at GraphLoader.scala:87, took 38.723849733 s
14/08/01 14:18:31 INFO GraphLoader: It took 39459 ms to load the edges
14/08/01 14:18:32 INFO GraphImpl: It took 13 ms to partition
14/08/01 14:18:32 INFO Analytics: GRAPHX: INPUT/data/sdd1/xiaodi/data/in-1.8-10m_aa
14/08/01 14:18:32 INFO Analytics: GRAPHX: Requirement PageRank0.01
14/08/01 14:18:32 INFO Analytics: GRAPHX: PatitionStrategySome(EdgePartition2D)
14/08/01 14:18:32 INFO SparkContext: Starting job: reduce at VertexRDD.scala:111
14/08/01 14:18:32 INFO DAGScheduler: Registering RDD 6 (mapPartitions at VertexRDD.scala:452)
14/08/01 14:18:32 INFO DAGScheduler: Registering RDD 12 (map at GraphImpl.scala:213)
14/08/01 14:18:32 INFO DAGScheduler: Registering RDD 16 (mapPartitions at VertexRDD.scala:452)
14/08/01 14:18:32 INFO DAGScheduler: Got job 1 (reduce at VertexRDD.scala:111) with 144 output partitions (allowLocal=false)
14/08/01 14:18:32 INFO DAGScheduler: Final stage: Stage 1(reduce at VertexRDD.scala:111)
14/08/01 14:18:32 INFO DAGScheduler: Parents of final stage: List(Stage 2, Stage 3)
14/08/01 14:18:32 INFO DAGScheduler: Missing parents: List(Stage 2, Stage 3)
14/08/01 14:18:32 INFO DAGScheduler: Submitting Stage 2 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[6] at mapPartitions at VertexRDD.scala:452), which has no missing parents
14/08/01 14:18:32 INFO DAGScheduler: Submitting 144 missing tasks from Stage 2 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[6] at mapPartitions at VertexRDD.scala:452)
14/08/01 14:18:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 144 tasks
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:120 as TID 144 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:120 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:72 as TID 145 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:72 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:24 as TID 146 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:24 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:48 as TID 147 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:48 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:0 as TID 148 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:0 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:96 as TID 149 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:96 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:121 as TID 150 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:121 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:73 as TID 151 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:73 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:25 as TID 152 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:25 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:49 as TID 153 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:49 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:1 as TID 154 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:1 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:97 as TID 155 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:97 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:122 as TID 156 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:122 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:74 as TID 157 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:74 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:26 as TID 158 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:26 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:50 as TID 159 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:50 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:2 as TID 160 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:2 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:98 as TID 161 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:98 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:123 as TID 162 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:123 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:75 as TID 163 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:75 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:27 as TID 164 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:27 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:51 as TID 165 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO DAGScheduler: Submitting Stage 4 (MappedRDD[12] at map at GraphImpl.scala:213), which has no missing parents
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:51 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:3 as TID 166 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:3 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:99 as TID 167 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:99 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:124 as TID 168 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:124 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:76 as TID 169 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:76 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:28 as TID 170 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:28 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:52 as TID 171 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:52 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:4 as TID 172 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:4 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:100 as TID 173 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:100 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:125 as TID 174 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:125 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:77 as TID 175 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:77 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:29 as TID 176 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:29 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:53 as TID 177 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:53 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:5 as TID 178 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:5 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:101 as TID 179 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:101 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:126 as TID 180 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO DAGScheduler: Submitting 144 missing tasks from Stage 4 (MappedRDD[12] at map at GraphImpl.scala:213)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:126 as 2648 bytes in 10 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:78 as TID 181 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:78 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 144 tasks
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:30 as TID 182 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:30 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:54 as TID 183 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:54 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:6 as TID 184 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:6 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:102 as TID 185 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:102 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:127 as TID 186 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:127 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:79 as TID 187 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:79 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:31 as TID 188 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:31 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:55 as TID 189 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:55 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:7 as TID 190 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:7 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:103 as TID 191 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:103 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:128 as TID 192 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:128 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:80 as TID 193 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:80 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:32 as TID 194 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:32 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:56 as TID 195 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:56 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:8 as TID 196 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:8 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:104 as TID 197 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:104 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:129 as TID 198 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:129 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:81 as TID 199 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:81 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:33 as TID 200 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:33 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:57 as TID 201 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:57 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:9 as TID 202 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:9 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:105 as TID 203 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:105 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:130 as TID 204 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:130 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:82 as TID 205 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:82 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:34 as TID 206 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:34 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:58 as TID 207 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:58 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:10 as TID 208 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:10 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:106 as TID 209 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:106 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:131 as TID 210 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:131 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:83 as TID 211 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:83 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:35 as TID 212 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:35 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:59 as TID 213 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:59 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:11 as TID 214 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:11 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:107 as TID 215 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:107 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:132 as TID 216 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:132 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:84 as TID 217 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:84 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:36 as TID 218 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:36 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:60 as TID 219 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:60 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:12 as TID 220 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:12 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:108 as TID 221 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:108 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:133 as TID 222 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:133 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:85 as TID 223 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:85 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:37 as TID 224 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:37 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:61 as TID 225 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:61 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:13 as TID 226 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:13 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:109 as TID 227 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:109 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:134 as TID 228 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:134 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:86 as TID 229 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:86 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:38 as TID 230 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:38 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:62 as TID 231 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:62 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:14 as TID 232 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:14 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:110 as TID 233 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:110 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:135 as TID 234 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:135 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:87 as TID 235 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:87 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:39 as TID 236 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:39 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:63 as TID 237 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:63 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:15 as TID 238 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:15 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:111 as TID 239 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:111 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:136 as TID 240 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:136 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:88 as TID 241 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:88 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:40 as TID 242 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:40 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:64 as TID 243 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:64 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:16 as TID 244 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:16 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:112 as TID 245 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:112 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:137 as TID 246 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:137 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:89 as TID 247 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:89 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:41 as TID 248 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:41 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:65 as TID 249 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:65 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:17 as TID 250 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:17 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:113 as TID 251 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:113 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:138 as TID 252 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:138 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:90 as TID 253 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:90 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:42 as TID 254 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:42 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:66 as TID 255 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:66 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:18 as TID 256 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:18 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:114 as TID 257 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:114 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:139 as TID 258 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:139 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:91 as TID 259 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:91 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:43 as TID 260 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:43 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:67 as TID 261 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:67 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:19 as TID 262 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:19 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:115 as TID 263 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:115 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:140 as TID 264 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:140 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:92 as TID 265 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:92 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:44 as TID 266 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:44 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:68 as TID 267 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:68 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:20 as TID 268 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:20 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:116 as TID 269 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:116 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:141 as TID 270 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:141 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:93 as TID 271 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:93 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:45 as TID 272 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:45 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:69 as TID 273 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:69 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:21 as TID 274 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:21 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:117 as TID 275 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:117 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:142 as TID 276 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:142 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:94 as TID 277 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:94 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:46 as TID 278 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:46 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:70 as TID 279 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:70 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:22 as TID 280 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:22 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:118 as TID 281 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:118 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:143 as TID 282 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:143 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:95 as TID 283 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:95 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:47 as TID 284 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:47 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:71 as TID 285 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:71 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:23 as TID 286 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:23 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:119 as TID 287 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:119 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 4.0:24 as TID 288 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 4.0:24 as 2850 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 4.0:25 as TID 289 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 4.0:25 as 2850 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 4.0:26 as TID 290 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 4.0:26 as 2850 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 248 (task 2.0:41)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/1c/shuffle_0_41_122 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 254 (task 2.0:42)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/2b/shuffle_0_42_10 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 242 (task 2.0:40)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/0d/shuffle_0_40_43 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:40 as TID 291 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:40 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 230 (task 2.0:38)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/00/shuffle_0_38_61 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:38 as TID 292 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:38 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 272 (task 2.0:45)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/13/shuffle_0_45_105 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:45 as TID 293 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:45 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 146 (task 2.0:24)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/0b/shuffle_0_24_25 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 224 (task 2.0:37)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/12/shuffle_0_37_136 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:37 as TID 294 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:37 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:24 as TID 295 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:24 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 164 (task 2.0:27)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/32/shuffle_0_27_7 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:27 as TID 296 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:27 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 170 (task 2.0:28)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/34/shuffle_0_28_132 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:28 as TID 297 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:28 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:42 as TID 298 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:42 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 182 (task 2.0:30)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/16/shuffle_0_30_139 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 278 (task 2.0:46)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/36/shuffle_0_46_134 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:46 as TID 299 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:46 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:30 as TID 300 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:30 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 260 (task 2.0:43)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/14/shuffle_0_43_128 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 200 (task 2.0:33)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/35/shuffle_0_33_126 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:33 as TID 301 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:33 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 218 (task 2.0:36)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/22/shuffle_0_36_50 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:36 as TID 302 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:36 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 236 (task 2.0:39)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/3f/shuffle_0_39_94 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:39 as TID 303 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:39 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 188 (task 2.0:31)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/17/shuffle_0_31_115 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:31 as TID 304 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:31 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 152 (task 2.0:25)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/04/shuffle_0_25_30 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:25 as TID 305 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:25 as 2648 bytes in 1 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:43 as TID 306 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:43 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 206 (task 2.0:34)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/04/shuffle_0_34_61 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 194 (task 2.0:32)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/2b/shuffle_0_32_99 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 212 (task 2.0:35)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/2b/shuffle_0_35_69 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:35 as TID 307 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:35 as 2648 bytes in 0 ms
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:32 as TID 308 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:32 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 284 (task 2.0:47)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/33/shuffle_0_47_114 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:47 as TID 309 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:47 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 176 (task 2.0:29)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/04/shuffle_0_29_56 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 4.0:48 as TID 310 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 4.0:48 as 2850 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 279 (task 2.0:70)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/2d/shuffle_0_70_51 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:29 as TID 311 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:29 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 158 (task 2.0:26)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/06/shuffle_0_26_44 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:26 as TID 312 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:26 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 266 (task 2.0:44)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/05/shuffle_0_44_61 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:70 as TID 313 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:70 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 255 (task 2.0:66)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/2a/shuffle_0_66_33 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:66 as TID 314 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:66 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 249 (task 2.0:65)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/3b/shuffle_0_65_110 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:65 as TID 315 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:65 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 189 (task 2.0:55)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0e/shuffle_0_55_59 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:55 as TID 316 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:55 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 231 (task 2.0:62)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/2e/shuffle_0_62_99 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:62 as TID 317 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:62 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 147 (task 2.0:48)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/04/shuffle_0_48_86 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:48 as TID 318 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:48 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 261 (task 2.0:67)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0a/shuffle_0_67_12 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:67 as TID 319 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:67 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 165 (task 2.0:51)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/1b/shuffle_0_51_113 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:51 as TID 320 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:51 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 177 (task 2.0:53)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/09/shuffle_0_53_5 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:53 as TID 321 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:53 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 153 (task 2.0:49)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/2e/shuffle_0_49_117 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:49 as TID 322 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:49 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 207 (task 2.0:58)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/02/shuffle_0_58_83 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:58 as TID 323 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:58 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 201 (task 2.0:57)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/2b/shuffle_0_57_69 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:57 as TID 324 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:57 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 219 (task 2.0:60)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/01/shuffle_0_60_131 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:60 as TID 325 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:60 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 273 (task 2.0:69)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/3f/shuffle_0_69_91 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:69 as TID 326 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:69 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 171 (task 2.0:52)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/16/shuffle_0_52_117 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:52 as TID 327 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:52 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 267 (task 2.0:68)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0f/shuffle_0_68_108 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:68 as TID 328 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:68 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 285 (task 2.0:71)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/3f/shuffle_0_71_122 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:71 as TID 329 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:71 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 195 (task 2.0:56)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0e/shuffle_0_56_49 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:56 as TID 330 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:56 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 183 (task 2.0:54)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0a/shuffle_0_54_5 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:54 as TID 331 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:54 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 159 (task 2.0:50)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0e/shuffle_0_50_65 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:50 as TID 332 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:50 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 213 (task 2.0:59)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0b/shuffle_0_59_16 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:59 as TID 333 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:59 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 243 (task 2.0:64)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/3b/shuffle_0_64_133 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:64 as TID 334 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:64 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 225 (task 2.0:61)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/24/shuffle_0_61_3 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:61 as TID 335 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:61 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 237 (task 2.0:63)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/36/shuffle_0_63_117 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 4.0:72 as TID 336 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 4.0:72 as 2850 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 175 (task 2.0:77)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/10/shuffle_0_77_39 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:77 as TID 337 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:77 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 199 (task 2.0:81)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/18/shuffle_0_81_18 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:81 as TID 338 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:81 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 271 (task 2.0:93)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/18/shuffle_0_93_118 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:93 as TID 339 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:93 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 253 (task 2.0:90)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/15/shuffle_0_90_68 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:90 as TID 340 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:90 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 169 (task 2.0:76)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/28/shuffle_0_76_74 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:76 as TID 341 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:76 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 145 (task 2.0:72)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2b/shuffle_0_72_95 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:72 as TID 342 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:72 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 157 (task 2.0:74)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2a/shuffle_0_74_74 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:74 as TID 343 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:74 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 163 (task 2.0:75)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/0b/shuffle_0_75_32 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:75 as TID 344 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:75 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 277 (task 2.0:94)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/35/shuffle_0_94_109 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:94 as TID 345 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:94 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 265 (task 2.0:92)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/39/shuffle_0_92_129 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:92 as TID 346 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:92 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 223 (task 2.0:85)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/1b/shuffle_0_85_101 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:85 as TID 347 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:85 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 211 (task 2.0:83)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/36/shuffle_0_83_119 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:83 as TID 348 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:83 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 241 (task 2.0:88)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/13/shuffle_0_88_128 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:88 as TID 349 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:88 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 205 (task 2.0:82)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/12/shuffle_0_82_46 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:82 as TID 350 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:82 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 259 (task 2.0:91)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/31/shuffle_0_91_65 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:91 as TID 351 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:91 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 235 (task 2.0:87)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/16/shuffle_0_87_104 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:87 as TID 352 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:87 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 229 (task 2.0:86)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/07/shuffle_0_86_61 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 4.0:0 as TID 353 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 4.0:0 as 2850 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 226 (task 2.0:13)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/0e/shuffle_0_13_17 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:86 as TID 354 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:86 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 187 (task 2.0:79)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/27/shuffle_0_79_87 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:79 as TID 355 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:79 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 247 (task 2.0:89)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/36/shuffle_0_89_135 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:13 as TID 356 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:13 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 238 (task 2.0:15)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/32/shuffle_0_15_125 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:89 as TID 357 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:89 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 193 (task 2.0:80)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/14/shuffle_0_80_68 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:80 as TID 358 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:80 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 181 (task 2.0:78)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/0a/shuffle_0_78_67 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:78 as TID 359 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:78 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 151 (task 2.0:73)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/30/shuffle_0_73_68 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:15 as TID 360 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:15 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 244 (task 2.0:16)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/21/shuffle_0_16_73 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:73 as TID 361 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:73 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 283 (task 2.0:95)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/07/shuffle_0_95_5 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:16 as TID 362 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:16 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 214 (task 2.0:11)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/19/shuffle_0_11_111 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:95 as TID 363 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:95 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 217 (task 2.0:84)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/19/shuffle_0_84_104 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:11 as TID 364 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:11 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 232 (task 2.0:14)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/06/shuffle_0_14_65 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:14 as TID 365 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:14 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 154 (task 2.0:1)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/14/shuffle_0_1_106 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:1 as TID 366 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:1 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 166 (task 2.0:3)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/3f/shuffle_0_3_86 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:3 as TID 367 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:3 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 160 (task 2.0:2)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/2e/shuffle_0_2_132 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:2 as TID 368 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:2 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 274 (task 2.0:21)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/09/shuffle_0_21_31 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:21 as TID 369 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:21 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 196 (task 2.0:8)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/00/shuffle_0_8_37 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:8 as TID 370 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:8 as 2648 bytes in 0 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 190 (task 2.0:7)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/33/shuffle_0_7_110 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:7 as TID 371 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:7 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 208 (task 2.0:10)
14/08/01 14:18:32 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/0e/shuffle_0_10_69 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:32 INFO TaskSetManager: Starting task 2.0:10 as TID 372 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:32 INFO TaskSetManager: Serialized task 2.0:10 as 2648 bytes in 1 ms
14/08/01 14:18:32 WARN TaskSetManager: Lost TID 172 (task 2.0:4)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/04/shuffle_0_4_15 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:4 as TID 373 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:4 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 280 (task 2.0:22)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/2a/shuffle_0_22_11 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:22 as TID 374 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:22 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 148 (task 2.0:0)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/03/shuffle_0_0_32 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:0 as TID 375 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:0 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 250 (task 2.0:17)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/37/shuffle_0_17_140 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:17 as TID 376 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:17 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:1 as TID 377 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:1 as 2850 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 220 (task 2.0:12)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/08/shuffle_0_12_65 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 202 (task 2.0:9)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/16/shuffle_0_9_94 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:9 as TID 378 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:9 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 184 (task 2.0:6)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/3e/shuffle_0_6_55 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:6 as TID 379 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:6 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 178 (task 2.0:5)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/1a/shuffle_0_5_94 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:5 as TID 380 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:5 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 256 (task 2.0:18)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/03/shuffle_0_18_88 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:18 as TID 381 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:18 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 262 (task 2.0:19)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/23/shuffle_0_19_67 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:19 as TID 382 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:19 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 286 (task 2.0:23)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/27/shuffle_0_23_64 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:23 as TID 383 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:23 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 268 (task 2.0:20)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/2a/shuffle_0_20_31 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:96 as TID 384 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:96 as 2850 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 221 (task 2.0:108)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/3c/shuffle_0_108_117 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:108 as TID 385 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:108 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 203 (task 2.0:105)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/06/shuffle_0_105_95 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:105 as TID 386 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:105 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 185 (task 2.0:102)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/21/shuffle_0_102_53 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:102 as TID 387 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:102 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 155 (task 2.0:97)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/1c/shuffle_0_97_110 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:97 as TID 388 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:97 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 275 (task 2.0:117)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/3a/shuffle_0_117_128 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:117 as TID 389 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:117 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 269 (task 2.0:116)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/20/shuffle_0_116_57 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:116 as TID 390 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:116 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 191 (task 2.0:103)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/1b/shuffle_0_103_27 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:103 as TID 391 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:103 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:97 as TID 392 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:97 as 2850 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 263 (task 2.0:115)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/33/shuffle_0_115_123 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 167 (task 2.0:99)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/14/shuffle_0_99_116 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:99 as TID 393 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:99 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 197 (task 2.0:104)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/1c/shuffle_0_104_38 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:104 as TID 394 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:104 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 149 (task 2.0:96)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/39/shuffle_0_96_125 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:96 as TID 395 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:96 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 239 (task 2.0:111)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/0c/shuffle_0_111_131 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:111 as TID 396 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:111 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 233 (task 2.0:110)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/37/shuffle_0_110_27 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:110 as TID 397 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:110 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 281 (task 2.0:118)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/28/shuffle_0_118_95 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:118 as TID 398 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:118 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 215 (task 2.0:107)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/34/shuffle_0_107_110 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:107 as TID 399 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:107 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 257 (task 2.0:114)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/20/shuffle_0_114_77 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:114 as TID 400 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:114 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 251 (task 2.0:113)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/00/shuffle_0_113_32 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:113 as TID 401 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:113 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 287 (task 2.0:119)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/27/shuffle_0_119_20 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:119 as TID 402 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:119 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 245 (task 2.0:112)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/32/shuffle_0_112_125 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:112 as TID 403 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:112 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:115 as TID 404 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:115 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 179 (task 2.0:101)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/13/shuffle_0_101_5 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 161 (task 2.0:98)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/24/shuffle_0_98_92 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:98 as TID 405 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:98 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:101 as TID 406 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:101 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:98 as TID 407 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:98 as 2850 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 209 (task 2.0:106)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/09/shuffle_0_106_82 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 173 (task 2.0:100)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/14/shuffle_0_100_7 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 227 (task 2.0:109)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/2c/shuffle_0_109_82 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:44 as TID 408 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:44 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 299 (task 2.0:46)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/2c/shuffle_0_46_4 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 216 (task 2.0:132)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/3a/shuffle_0_132_46 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:132 as TID 409 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:132 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 298 (task 2.0:42)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/18/shuffle_0_42_125 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:42 as TID 410 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:42 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:120 as TID 411 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:120 as 2850 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 186 (task 2.0:127)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/23/shuffle_0_127_65 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 297 (task 2.0:28)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/23/shuffle_0_28_10 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:28 as TID 412 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:28 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:127 as TID 413 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:127 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 210 (task 2.0:131)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/3e/shuffle_0_131_30 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:46 as TID 414 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:46 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 296 (task 2.0:27)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/0c/shuffle_0_27_18 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:131 as TID 415 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:131 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 156 (task 2.0:122)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/1e/shuffle_0_122_10 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:122 as TID 416 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:122 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:27 as TID 417 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:27 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 264 (task 2.0:140)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/35/shuffle_0_140_48 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 192 (task 2.0:128)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/16/shuffle_0_128_124 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:128 as TID 418 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:128 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 295 (task 2.0:24)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/06/shuffle_0_24_20 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 234 (task 2.0:135)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/37/shuffle_0_135_8 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:135 as TID 419 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:135 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:140 as TID 420 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:140 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 282 (task 2.0:143)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/3f/shuffle_0_143_96 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:143 as TID 421 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:143 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 276 (task 2.0:142)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/3e/shuffle_0_142_85 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:24 as TID 422 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:24 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 292 (task 2.0:38)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/07/shuffle_0_38_68 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:142 as TID 423 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:142 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:121 as TID 424 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:121 as 2850 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 270 (task 2.0:141)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/36/shuffle_0_141_37 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 258 (task 2.0:139)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/36/shuffle_0_139_124 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 174 (task 2.0:125)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/3c/shuffle_0_125_15 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:125 as TID 425 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:125 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:139 as TID 426 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:139 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 198 (task 2.0:129)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/02/shuffle_0_129_35 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:129 as TID 427 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:129 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 144 (task 2.0:120)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/16/shuffle_0_120_16 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:120 as TID 428 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:120 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:141 as TID 429 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:141 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 180 (task 2.0:126)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/1f/shuffle_0_126_13 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 228 (task 2.0:134)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/0d/shuffle_0_134_131 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:134 as TID 430 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:134 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 162 (task 2.0:123)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/32/shuffle_0_123_136 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:123 as TID 431 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:123 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 168 (task 2.0:124)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/18/shuffle_0_124_108 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:124 as TID 432 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:124 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 252 (task 2.0:138)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/03/shuffle_0_138_21 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:138 as TID 433 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:138 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 222 (task 2.0:133)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/3d/shuffle_0_133_33 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:133 as TID 434 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:133 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 240 (task 2.0:136)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/04/shuffle_0_136_40 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:136 as TID 435 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:136 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 150 (task 2.0:121)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/16/shuffle_0_121_28 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:121 as TID 436 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:121 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 246 (task 2.0:137)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/33/shuffle_0_137_123 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:137 as TID 437 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:137 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 204 (task 2.0:130)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/2e/shuffle_0_130_103 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:38 as TID 438 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:38 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 312 (task 2.0:26)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/04/shuffle_0_26_86 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:26 as TID 439 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:26 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 303 (task 2.0:39)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/0f/shuffle_0_39_3 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:39 as TID 440 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:39 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 305 (task 2.0:25)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/00/shuffle_0_25_92 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:25 as TID 441 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:25 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 301 (task 2.0:33)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/0a/shuffle_0_33_77 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:33 as TID 442 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:33 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 304 (task 2.0:31)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/1a/shuffle_0_31_112 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:31 as TID 443 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:31 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 300 (task 2.0:30)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/27/shuffle_0_30_71 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:63 as TID 444 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:63 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 319 (task 2.0:67)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/21/shuffle_0_67_80 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:67 as TID 445 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:67 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 318 (task 2.0:48)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/2b/shuffle_0_48_16 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:48 as TID 446 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:48 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 317 (task 2.0:62)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/11/shuffle_0_62_47 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:62 as TID 447 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:62 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 316 (task 2.0:55)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/34/shuffle_0_55_127 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:55 as TID 448 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:55 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 320 (task 2.0:51)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0d/shuffle_0_51_32 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:30 as TID 449 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:30 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 309 (task 2.0:47)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/04/shuffle_0_47_74 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:47 as TID 450 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:47 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 311 (task 2.0:29)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/26/shuffle_0_29_47 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:29 as TID 451 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:29 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 308 (task 2.0:32)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/26/shuffle_0_32_50 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:32 as TID 452 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:32 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 306 (task 2.0:43)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/25/shuffle_0_43_60 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:51 as TID 453 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:51 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 327 (task 2.0:52)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/2c/shuffle_0_52_76 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:52 as TID 454 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:52 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 329 (task 2.0:71)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0d/shuffle_0_71_52 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:71 as TID 455 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:71 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 325 (task 2.0:60)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/10/shuffle_0_60_22 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:60 as TID 456 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:60 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 324 (task 2.0:57)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/29/shuffle_0_57_23 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:57 as TID 457 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:57 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 323 (task 2.0:58)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/00/shuffle_0_58_81 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:58 as TID 458 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:58 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 321 (task 2.0:53)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/38/shuffle_0_53_125 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:53 as TID 459 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:53 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 330 (task 2.0:56)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/32/shuffle_0_56_128 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:56 as TID 460 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:56 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 334 (task 2.0:64)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/1e/shuffle_0_64_141 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:64 as TID 461 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:64 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 332 (task 2.0:50)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/2f/shuffle_0_50_55 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:50 as TID 462 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:50 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 331 (task 2.0:54)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/3c/shuffle_0_54_142 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:54 as TID 463 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:54 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 328 (task 2.0:68)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/2a/shuffle_0_68_13 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:68 as TID 464 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:68 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 326 (task 2.0:69)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0e/shuffle_0_69_18 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:69 as TID 465 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:69 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 335 (task 2.0:61)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/08/shuffle_0_61_70 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:84 as TID 466 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:84 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 345 (task 2.0:94)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2c/shuffle_0_94_52 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:94 as TID 467 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:94 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 347 (task 2.0:85)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/0a/shuffle_0_85_30 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:85 as TID 468 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:85 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 344 (task 2.0:75)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2a/shuffle_0_75_42 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:75 as TID 469 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:75 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 342 (task 2.0:72)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2e/shuffle_0_72_98 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:72 as TID 470 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:72 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 343 (task 2.0:74)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/06/shuffle_0_74_81 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:74 as TID 471 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:74 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 341 (task 2.0:76)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/0b/shuffle_0_76_22 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:76 as TID 472 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:76 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 358 (task 2.0:80)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/1e/shuffle_0_80_0 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:80 as TID 473 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:80 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 352 (task 2.0:87)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/25/shuffle_0_87_82 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:87 as TID 474 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:87 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 357 (task 2.0:89)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/38/shuffle_0_89_133 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:89 as TID 475 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:89 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 355 (task 2.0:79)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/25/shuffle_0_79_41 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:79 as TID 476 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:79 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 351 (task 2.0:91)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/34/shuffle_0_91_68 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:91 as TID 477 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:91 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 346 (task 2.0:92)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/0d/shuffle_0_92_84 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:92 as TID 478 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:92 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 363 (task 2.0:95)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/0b/shuffle_0_95_9 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:95 as TID 479 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:95 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 354 (task 2.0:86)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/05/shuffle_0_86_81 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:86 as TID 480 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:86 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 350 (task 2.0:82)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2f/shuffle_0_82_32 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:82 as TID 481 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:82 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 348 (task 2.0:83)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/1e/shuffle_0_83_122 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:83 as TID 482 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:83 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 359 (task 2.0:78)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/0a/shuffle_0_78_45 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:20 as TID 483 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:20 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 376 (task 2.0:17)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/15/shuffle_0_17_131 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:17 as TID 484 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:17 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 369 (task 2.0:21)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/2f/shuffle_0_21_48 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:21 as TID 485 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:21 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 372 (task 2.0:10)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/2b/shuffle_0_10_33 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:10 as TID 486 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:10 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 380 (task 2.0:5)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/18/shuffle_0_5_106 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:5 as TID 487 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:5 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 368 (task 2.0:2)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/26/shuffle_0_2_26 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:109 as TID 488 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:109 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:100 as TID 489 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:100 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 393 (task 2.0:99)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/39/shuffle_0_99_122 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 390 (task 2.0:116)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/04/shuffle_0_116_20 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:116 as TID 490 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:116 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 395 (task 2.0:96)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/2b/shuffle_0_96_31 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:2 as TID 491 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:2 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 371 (task 2.0:7)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/3b/shuffle_0_7_86 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:7 as TID 492 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:7 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 367 (task 2.0:3)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/04/shuffle_0_3_25 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:96 as TID 493 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:96 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 389 (task 2.0:117)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/24/shuffle_0_117_21 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:3 as TID 494 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:3 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 375 (task 2.0:0)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/0b/shuffle_0_0_142 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:117 as TID 495 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:117 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 385 (task 2.0:108)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/22/shuffle_0_108_58 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:0 as TID 496 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:0 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 383 (task 2.0:23)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/2d/shuffle_0_23_26 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:23 as TID 497 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:23 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 381 (task 2.0:18)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/22/shuffle_0_18_76 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:18 as TID 498 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:18 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 379 (task 2.0:6)
14/08/01 14:18:33 INFO TaskSetManager: Loss was due to java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/3e/shuffle_0_6_55 (Too many open files) [duplicate 1]
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:108 as TID 499 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:108 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 406 (task 2.0:101)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/01/shuffle_0_101_74 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:6 as TID 500 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:6 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:101 as TID 501 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:101 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:99 as TID 502 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:99 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 398 (task 2.0:118)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/15/shuffle_0_118_133 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 370 (task 2.0:8)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/33/shuffle_0_8_131 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 400 (task 2.0:114)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/30/shuffle_0_114_0 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 353 (task 4.0:0)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/3d/shuffle_2_0_94 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:8 as TID 503 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:8 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:114 as TID 504 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:114 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 399 (task 2.0:107)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/06/shuffle_0_107_97 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:12 as TID 505 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:12 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 378 (task 2.0:9)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/00/shuffle_0_9_27 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:107 as TID 506 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:107 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 396 (task 2.0:111)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/17/shuffle_0_111_28 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:9 as TID 507 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:9 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:111 as TID 508 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:111 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 373 (task 2.0:4)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/3d/shuffle_0_4_30 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 394 (task 2.0:104)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/08/shuffle_0_104_81 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:104 as TID 509 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:104 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 397 (task 2.0:110)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/25/shuffle_0_110_90 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:4 as TID 510 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:4 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 374 (task 2.0:22)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/30/shuffle_0_22_17 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:22 as TID 511 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:22 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 382 (task 2.0:19)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/28/shuffle_0_19_28 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:43 as TID 512 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:43 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 414 (task 2.0:46)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/06/shuffle_0_46_86 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:46 as TID 513 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:46 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:34 as TID 514 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:34 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 410 (task 2.0:42)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/05/shuffle_0_42_81 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 412 (task 2.0:28)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/0f/shuffle_0_28_126 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:110 as TID 515 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:110 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 405 (task 2.0:98)
14/08/01 14:18:33 INFO TaskSetManager: Loss was due to java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/24/shuffle_0_98_92 (Too many open files) [duplicate 1]
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:98 as TID 516 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:98 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 404 (task 2.0:115)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/20/shuffle_0_115_23 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:115 as TID 517 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:115 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 402 (task 2.0:119)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/06/shuffle_0_119_32 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:119 as TID 518 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:119 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 403 (task 2.0:112)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/11/shuffle_0_112_113 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:28 as TID 519 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:28 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 417 (task 2.0:27)
14/08/01 14:18:33 INFO TaskSetManager: Loss was due to java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/0c/shuffle_0_27_18 (Too many open files) [duplicate 1]
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:130 as TID 520 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:130 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 426 (task 2.0:139)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/33/shuffle_0_139_121 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 425 (task 2.0:125)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/04/shuffle_0_125_73 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:125 as TID 521 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:125 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:139 as TID 522 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:139 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 421 (task 2.0:143)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/19/shuffle_0_143_69 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:143 as TID 523 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:143 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:126 as TID 524 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:126 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:122 as TID 525 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:122 as 2850 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 419 (task 2.0:135)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/1b/shuffle_0_135_26 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 415 (task 2.0:131)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/3d/shuffle_0_131_31 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 420 (task 2.0:140)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/2f/shuffle_0_140_116 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:27 as TID 526 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:27 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 422 (task 2.0:24)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/30/shuffle_0_24_8 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:140 as TID 527 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:140 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 429 (task 2.0:141)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/0b/shuffle_0_141_1 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:141 as TID 528 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:141 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 428 (task 2.0:120)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/37/shuffle_0_120_48 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 427 (task 2.0:129)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/1e/shuffle_0_129_28 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:129 as TID 529 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:129 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:120 as TID 530 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:120 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:131 as TID 531 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:131 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 433 (task 2.0:138)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/25/shuffle_0_138_52 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 435 (task 2.0:136)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/19/shuffle_0_136_119 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 431 (task 2.0:123)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/20/shuffle_0_123_86 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:123 as TID 532 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:123 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:136 as TID 533 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:136 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 430 (task 2.0:134)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/1e/shuffle_0_134_11 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:134 as TID 534 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:134 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 432 (task 2.0:124)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/1a/shuffle_0_124_16 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:61 as TID 535 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:61 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:49 as TID 536 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:49 as 2850 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 313 in 830 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 1/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 70)
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 322 in 811 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 2/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 49)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:50 as TID 537 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:50 as 2850 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 333 in 779 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 3/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 59)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:51 as TID 538 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:51 as 2850 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 315 in 850 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 4/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 65)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:52 as TID 539 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:52 as 2850 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 314 in 861 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 5/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 66)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:124 as TID 540 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:124 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 437 (task 2.0:137)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/23/shuffle_0_137_42 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:137 as TID 541 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:137 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:138 as TID 542 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:138 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 436 (task 2.0:121)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/22/shuffle_0_121_60 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 434 (task 2.0:133)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/3f/shuffle_0_133_97 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:78 as TID 543 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:78 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:73 as TID 544 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:73 as 2850 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 467 (task 2.0:94)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/14/shuffle_0_94_49 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:94 as TID 545 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:94 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 466 (task 2.0:84)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2e/shuffle_0_84_77 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 468 (task 2.0:85)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2d/shuffle_0_85_66 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:24 as TID 546 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:24 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 450 (task 2.0:47)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/10/shuffle_0_47_106 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:47 as TID 547 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:47 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 452 (task 2.0:32)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/0d/shuffle_0_32_46 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:32 as TID 548 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:32 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 443 (task 2.0:31)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-c117/17/shuffle_0_31_137 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:85 as TID 549 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:85 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 475 (task 2.0:89)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2e/shuffle_0_89_27 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:31 as TID 550 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:31 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 293 in 1002 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 6/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 45)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:89 as TID 551 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:89 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 473 (task 2.0:80)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/38/shuffle_0_80_17 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:42 as TID 552 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:42 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 307 in 938 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 7/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 35)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:41 as TID 553 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:41 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 408 in 580 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 8/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 44)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:80 as TID 554 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:80 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 469 (task 2.0:75)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2e/shuffle_0_75_68 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:19 as TID 555 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:19 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 483 (task 2.0:20)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/1d/shuffle_0_20_120 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:27 as TID 556 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:27 as 2850 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 294 in 1017 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 9/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 37)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:28 as TID 557 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:28 as 2850 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 302 in 989 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 10/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 36)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:29 as TID 558 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:29 as 2850 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 291 in 1046 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 11/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 40)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:75 as TID 559 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:75 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 479 (task 2.0:95)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/13/shuffle_0_95_16 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:20 as TID 560 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:20 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 487 (task 2.0:5)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/16/shuffle_0_5_104 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:95 as TID 561 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:95 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 474 (task 2.0:87)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2c/shuffle_0_87_23 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:112 as TID 562 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:112 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 488 (task 2.0:109)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/3e/shuffle_0_109_118 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:5 as TID 563 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:5 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 484 (task 2.0:17)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/1e/shuffle_0_17_82 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:109 as TID 564 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:109 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 493 (task 2.0:96)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/0b/shuffle_0_96_86 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:96 as TID 565 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:96 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 489 (task 2.0:100)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/0c/shuffle_0_100_120 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:87 as TID 566 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:87 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 472 (task 2.0:76)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2e/shuffle_0_76_36 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:76 as TID 567 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:76 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 471 (task 2.0:74)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/2d/shuffle_0_74_33 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:74 as TID 568 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:74 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 470 (task 2.0:72)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/06/shuffle_0_72_5 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:17 as TID 569 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:17 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 492 (task 2.0:7)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/39/shuffle_0_7_84 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:72 as TID 570 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:72 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 476 (task 2.0:79)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141757-0274/30/shuffle_0_79_107 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:7 as TID 571 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:7 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 486 (task 2.0:10)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/34/shuffle_0_10_128 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:53 as TID 572 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:53 as 2850 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 464 (task 2.0:68)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/22/shuffle_0_68_93 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:68 as TID 573 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:68 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 448 (task 2.0:55)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/3d/shuffle_0_55_140 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:55 as TID 574 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:55 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 445 in 467 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 12/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 67)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:54 as TID 575 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:54 as 2850 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 444 in 477 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 13/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 63)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:100 as TID 576 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:100 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 501 (task 2.0:101)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/3c/shuffle_0_101_79 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:55 as TID 577 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:55 as 2850 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 457 (task 2.0:57)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/0a/shuffle_0_57_13 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:57 as TID 578 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:57 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 456 (task 2.0:60)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/15/shuffle_0_60_27 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 453 (task 2.0:51)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/32/shuffle_0_51_48 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:51 as TID 579 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:51 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:60 as TID 580 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:60 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 447 (task 2.0:62)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-a9d3/28/shuffle_0_62_6 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:101 as TID 581 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:101 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 495 (task 2.0:117)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/32/shuffle_0_117_142 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:117 as TID 582 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:117 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 490 (task 2.0:116)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/39/shuffle_0_116_7 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:30 as TID 583 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:30 as 2850 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 439 in 517 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 14/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 26)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:10 as TID 584 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:10 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 494 (task 2.0:3)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/05/shuffle_0_3_48 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:3 as TID 585 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:3 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 485 (task 2.0:21)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/37/shuffle_0_21_136 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:116 as TID 586 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:116 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 508 (task 2.0:111)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/15/shuffle_0_111_118 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:111 as TID 587 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:111 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 504 (task 2.0:114)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/1f/shuffle_0_114_12 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:114 as TID 588 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:114 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 506 (task 2.0:107)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/14/shuffle_0_107_121 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:107 as TID 589 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:107 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 499 (task 2.0:108)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/15/shuffle_0_108_143 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:21 as TID 590 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:21 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 498 (task 2.0:18)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/0f/shuffle_0_18_2 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:18 as TID 591 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:18 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 500 (task 2.0:6)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/04/shuffle_0_6_17 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:6 as TID 592 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:6 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:62 as TID 593 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:62 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:31 as TID 594 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:31 as 2850 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 454 in 498 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 15/144)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 507 (task 2.0:9)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 52)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/19/shuffle_0_9_125 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:9 as TID 595 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:9 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:32 as TID 596 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:32 as 2850 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 440 in 553 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 16/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 39)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:0 as TID 597 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:0 as 2850 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:2 as TID 598 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:2 as 2850 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 441 in 561 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 17/144)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 497 (task 2.0:23)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 25)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/0a/shuffle_0_23_78 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 491 (task 2.0:2)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/24/shuffle_0_2_24 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 505 (task 2.0:12)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/25/shuffle_0_12_73 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:133 as TID 599 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:133 as 2648 bytes in 1 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 523 (task 2.0:143)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/0e/shuffle_0_143_101 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:12 as TID 600 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:12 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 496 (task 2.0:0)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/3d/shuffle_0_0_92 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:79 as TID 601 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:79 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 337 in 1000 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 18/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 77)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:56 as TID 602 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:56 as 2850 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 460 in 539 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 19/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 56)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 503 (task 2.0:8)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/14/shuffle_0_8_121 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:8 as TID 603 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:8 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:84 as TID 604 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:84 as 2648 bytes in 0 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:143 as TID 605 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:143 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 361 in 966 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 20/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 73)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 521 (task 2.0:125)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/00/shuffle_0_125_77 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 438 in 648 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 21/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 38)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:33 as TID 606 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:33 as 2850 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:74 as TID 607 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:74 as 2850 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 349 in 1026 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 22/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 88)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:57 as TID 608 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:57 as 2850 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:108 as TID 609 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:108 as 2648 bytes in 1 ms
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 71)
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 455 in 622 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 23/144)
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 517 (task 2.0:115)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/27/shuffle_0_115_60 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 4.0:58 as TID 610 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 4.0:58 as 2850 bytes in 1 ms
14/08/01 14:18:33 INFO TaskSetManager: Finished TID 462 in 615 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 24/144)
14/08/01 14:18:33 INFO DAGScheduler: Completed ShuffleMapTask(2, 50)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:125 as TID 611 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:125 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 524 (task 2.0:126)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/39/shuffle_0_126_118 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:115 as TID 612 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:115 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 516 (task 2.0:98)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/29/shuffle_0_98_53 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:98 as TID 613 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:33 INFO TaskSetManager: Serialized task 2.0:98 as 2648 bytes in 0 ms
14/08/01 14:18:33 WARN TaskSetManager: Lost TID 515 (task 2.0:110)
14/08/01 14:18:33 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/11/shuffle_0_110_115 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:33 INFO TaskSetManager: Starting task 2.0:126 as TID 614 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:126 as 2648 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 522 (task 2.0:139)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/1a/shuffle_0_139_117 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:110 as TID 615 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:110 as 2648 bytes in 1 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 509 (task 2.0:104)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/05/shuffle_0_104_84 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:59 as TID 616 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:59 as 2850 bytes in 0 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 461 in 641 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 25/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 64)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:34 as TID 617 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:34 as 2850 bytes in 0 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 442 in 710 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 26/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 33)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:35 as TID 618 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:35 as 2850 bytes in 1 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 449 in 695 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 27/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 30)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:60 as TID 619 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:60 as 2850 bytes in 0 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 446 in 712 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 28/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 48)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:139 as TID 620 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:139 as 2648 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 528 (task 2.0:141)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/21/shuffle_0_141_81 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:141 as TID 621 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:141 as 2648 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 527 (task 2.0:140)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/3b/shuffle_0_140_86 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:104 as TID 622 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:104 as 2648 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 518 (task 2.0:119)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/06/shuffle_0_119_76 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:0 as TID 623 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:0 as 2648 bytes in 1 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 511 (task 2.0:22)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/29/shuffle_0_22_76 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:36 as TID 624 on executor 4: brick1.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:36 as 2850 bytes in 0 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 451 in 714 ms on brick1.ipads-lab.se.sjtu.edu.cn (progress: 29/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 29)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:22 as TID 625 on executor 2: brick0.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:22 as 2648 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 510 (task 2.0:4)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141756-3bea/33/shuffle_0_4_113 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:75 as TID 626 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:75 as 2850 bytes in 1 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 338 in 1162 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 30/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 81)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:76 as TID 627 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:76 as 2850 bytes in 1 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 340 in 1162 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 31/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 90)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:77 as TID 628 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:77 as 2850 bytes in 0 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 339 in 1171 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 32/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 93)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:78 as TID 629 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:78 as 2850 bytes in 1 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 481 in 654 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 33/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 82)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:61 as TID 630 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:61 as 2850 bytes in 0 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 459 in 725 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 34/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 53)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:140 as TID 631 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:140 as 2648 bytes in 1 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 532 (task 2.0:123)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/1d/shuffle_0_123_67 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:123 as TID 632 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:123 as 2648 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 533 (task 2.0:136)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/28/shuffle_0_136_91 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:62 as TID 633 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:62 as 2850 bytes in 0 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 463 in 731 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 35/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 54)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:63 as TID 634 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:63 as 2850 bytes in 1 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 465 in 735 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 36/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 69)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:136 as TID 635 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:136 as 2648 bytes in 1 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 534 (task 2.0:134)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/23/shuffle_0_134_50 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:134 as TID 636 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:134 as 2648 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 529 (task 2.0:129)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/26/shuffle_0_129_64 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:79 as TID 637 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:79 as 2850 bytes in 1 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 482 in 701 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 37/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 83)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:129 as TID 638 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:129 as 2648 bytes in 1 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 530 (task 2.0:120)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/3e/shuffle_0_120_85 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:80 as TID 639 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:80 as 2850 bytes in 0 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 477 in 736 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 38/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 91)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:81 as TID 640 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:81 as 2850 bytes in 1 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 478 in 741 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 39/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 92)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:64 as TID 641 on executor 3: brick4.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:64 as 2850 bytes in 1 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 458 in 808 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 40/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 58)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:82 as TID 642 on executor 5: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:82 as 2850 bytes in 1 ms
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 480 in 755 ms on brick3.ipads-lab.se.sjtu.edu.cn (progress: 41/144)
14/08/01 14:18:34 INFO DAGScheduler: Completed ShuffleMapTask(2, 86)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:120 as TID 643 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:120 as 2648 bytes in 1 ms
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:121 as TID 644 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:121 as 2648 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 542 (task 2.0:138)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/26/shuffle_0_138_51 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 531 (task 2.0:131)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/10/shuffle_0_131_115 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:131 as TID 645 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:131 as 2648 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 541 (task 2.0:137)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/16/shuffle_0_137_137 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:137 as TID 646 on executor 1: brick5.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:137 as 2648 bytes in 1 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 540 (task 2.0:124)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-67e7/03/shuffle_0_124_84 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:119 as TID 647 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:119 as 2648 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 564 (task 2.0:109)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/18/shuffle_0_109_123 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 2.0:109 as TID 648 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 2.0:109 as 2648 bytes in 1 ms
14/08/01 14:18:34 WARN TaskSetManager: Lost TID 565 (task 2.0:96)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/2b/shuffle_0_96_75 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 ERROR TaskSetManager: Task 2.0:96 failed 4 times; aborting job
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:99 as TID 649 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:99 as 2850 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/12/shuffle_0_112_136 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:100 as TID 650 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:100 as 2850 bytes in 0 ms
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/19/shuffle_0_111_48 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Starting task 4.0:101 as TID 651 on executor 0: brick2.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/08/01 14:18:34 INFO TaskSetManager: Serialized task 4.0:101 as 2850 bytes in 1 ms
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/3b/shuffle_0_117_107 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSchedulerImpl: Cancelling stage 2
14/08/01 14:18:34 INFO TaskSchedulerImpl: Stage 2 was cancelled
14/08/01 14:18:34 INFO TaskSchedulerImpl: Cancelling stage 4
14/08/01 14:18:34 INFO TaskSchedulerImpl: Stage 4 was cancelled
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/0f/shuffle_0_101_1 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/36/shuffle_0_100_119 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO DAGScheduler: Failed to run reduce at VertexRDD.scala:111
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 2.0:96 failed 4 times, most recent failure: Exception failure in TID 565 on host brick2.ipads-lab.se.sjtu.edu.cn: java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/2b/shuffle_0_96_75 (Too many open files)
        java.io.FileOutputStream.open(Native Method)
        java.io.FileOutputStream.<init>(FileOutputStream.java:221)
        org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
        org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
        org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
        org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
        scala.collection.Iterator$class.foreach(Iterator.scala:727)
        scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
        org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
        org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
        org.apache.spark.scheduler.Task.run(Task.scala:51)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.Thread.run(Thread.java:745)
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1041)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1025)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1023)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1023)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:631)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:631)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:631)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1226)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)
	at akka.actor.ActorCell.invoke(ActorCell.scala:456)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)
	at akka.dispatch.Mailbox.run(Mailbox.scala:219)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 364 in 1263 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 42/144)
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 360 in 1280 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 43/144)
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 535 in 615 ms on brick4.ipads-lab.se.sjtu.edu.cn (progress: 44/144)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/26/shuffle_0_107_20 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 WARN TaskSetManager: Loss was due to java.io.FileNotFoundException
java.io.FileNotFoundException: /tmp/spark-local-20140801141758-b71e/13/shuffle_0_116_133 (Too many open files)
	at java.io.FileOutputStream.open(Native Method)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:221)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(BlockObjectWriter.scala:116)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(BlockObjectWriter.scala:177)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:59)
	at org.apache.spark.shuffle.hash.HashShuffleWriter$$anonfun$write$1.apply(HashShuffleWriter.scala:57)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.shuffle.hash.HashShuffleWriter.write(HashShuffleWriter.scala:57)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:147)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:97)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:187)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 356 in 1302 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 45/144)
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 365 in 1280 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 46/144)
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 362 in 1294 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 47/144)
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 366 in 1289 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 48/144)
14/08/01 14:18:34 INFO TaskSetManager: Finished TID 555 in 546 ms on brick0.ipads-lab.se.sjtu.edu.cn (progress: 49/144)
