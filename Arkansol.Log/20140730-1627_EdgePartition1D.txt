Warning: SPARK_MEM is deprecated, please use a more specific config option
(e.g., spark.executor.memory or SPARK_DRIVER_MEMORY).
======================================
|             PageRank               |
======================================
14/07/30 16:27:16 INFO SparkConf: Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
14/07/30 16:27:16 WARN SparkConf: 
SPARK_JAVA_OPTS was detected (set to '-Dspark.executor.memory=60g').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
14/07/30 16:27:16 WARN SparkConf: Setting 'spark.executor.extraJavaOptions' to '-Dspark.executor.memory=60g' as a work-around.
14/07/30 16:27:16 WARN SparkConf: Setting 'spark.driver.extraJavaOptions' to '-Dspark.executor.memory=60g' as a work-around.
14/07/30 16:27:16 INFO SecurityManager: Changing view acls to: xiaodi
14/07/30 16:27:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xiaodi)
14/07/30 16:27:17 INFO Slf4jLogger: Slf4jLogger started
14/07/30 16:27:17 INFO Remoting: Starting remoting
14/07/30 16:27:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@brick0.ipads-lab.se.sjtu.edu.cn:50847]
14/07/30 16:27:17 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@brick0.ipads-lab.se.sjtu.edu.cn:50847]
14/07/30 16:27:17 INFO SparkEnv: Registering MapOutputTracker
14/07/30 16:27:17 INFO SparkEnv: Registering BlockManagerMaster
14/07/30 16:27:17 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140730162717-4ca1
14/07/30 16:27:17 INFO ConnectionManager: Bound socket to port 44130 with id = ConnectionManagerId(brick0.ipads-lab.se.sjtu.edu.cn,44130)
14/07/30 16:27:17 INFO MemoryStore: MemoryStore started with capacity 34.5 GB
14/07/30 16:27:17 INFO BlockManagerMaster: Trying to register BlockManager
14/07/30 16:27:17 INFO BlockManagerInfo: Registering block manager brick0.ipads-lab.se.sjtu.edu.cn:44130 with 34.5 GB RAM
14/07/30 16:27:17 INFO BlockManagerMaster: Registered BlockManager
14/07/30 16:27:17 INFO HttpServer: Starting HTTP Server
14/07/30 16:27:17 INFO HttpBroadcast: Broadcast server started at http://192.168.12.124:36281
14/07/30 16:27:17 INFO HttpFileServer: HTTP File server directory is /tmp/spark-bfde7ffc-7bb5-4c10-bec9-6892e9a7a51b
14/07/30 16:27:17 INFO HttpServer: Starting HTTP Server
14/07/30 16:27:18 INFO SparkUI: Started SparkUI at http://brick0.ipads-lab.se.sjtu.edu.cn:4040
14/07/30 16:27:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/07/30 16:27:18 INFO EventLoggingListener: Logging events to /tmp/spark-events/pagerank(-data-sdd1-xiaodi-data-soc-livejournal1.txt)-some(edgepartition1d)-1406708838758
14/07/30 16:27:19 INFO SparkContext: Added JAR file:/data/sdd1/xiaodi/spark/examples/target/scala-2.10/spark-examples-1.1.0-SNAPSHOT-hadoop1.0.4.jar at http://192.168.12.124:59647/jars/spark-examples-1.1.0-SNAPSHOT-hadoop1.0.4.jar with timestamp 1406708839248
14/07/30 16:27:19 INFO AppClient$ClientActor: Connecting to master spark://brick0:7077...
14/07/30 16:27:19 INFO MemoryStore: ensureFreeSpace(42201) called with curMem=0, maxMem=37044092928
14/07/30 16:27:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 41.2 KB, free 34.5 GB)
14/07/30 16:27:19 WARN LoadSnappy: Snappy native library not loaded
14/07/30 16:27:19 INFO FileInputFormat: Total input paths to process : 1
14/07/30 16:27:19 INFO SparkContext: Starting job: count at GraphLoader.scala:87
14/07/30 16:27:20 INFO DAGScheduler: Got job 0 (count at GraphLoader.scala:87) with 4 output partitions (allowLocal=false)
14/07/30 16:27:20 INFO DAGScheduler: Final stage: Stage 0(count at GraphLoader.scala:87)
14/07/30 16:27:20 INFO DAGScheduler: Parents of final stage: List()
14/07/30 16:27:20 INFO DAGScheduler: Missing parents: List()
14/07/30 16:27:20 INFO DAGScheduler: Submitting Stage 0 (GraphLoader.edgeListFile - edges (/data/sdd1/xiaodi/data/soc-LiveJournal1.txt) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68), which has no missing parents
14/07/30 16:27:20 INFO DAGScheduler: Submitting 4 missing tasks from Stage 0 (GraphLoader.edgeListFile - edges (/data/sdd1/xiaodi/data/soc-LiveJournal1.txt) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68)
14/07/30 16:27:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
14/07/30 16:27:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:27:39 INFO AppClient$ClientActor: Connecting to master spark://brick0:7077...
14/07/30 16:27:49 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20140730162748-0025
14/07/30 16:27:49 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20140730162748-0026
14/07/30 16:27:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:28:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:28:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:28:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:28:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:29:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:29:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:29:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:29:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:30:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:30:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:30:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:30:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:31:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:31:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:31:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:31:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:32:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:32:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:32:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:32:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:33:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:33:20 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:33:35 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:33:50 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:34:02 INFO AppClient$ClientActor: Executor added: app-20140730162748-0026/0 on worker-20140729100506-brick3.ipads-lab.se.sjtu.edu.cn-56586 (brick3.ipads-lab.se.sjtu.edu.cn:56586) with 24 cores
14/07/30 16:34:02 INFO SparkDeploySchedulerBackend: Granted executor ID app-20140730162748-0026/0 on hostPort brick3.ipads-lab.se.sjtu.edu.cn:56586 with 24 cores, 60.0 GB RAM
14/07/30 16:34:02 INFO AppClient$ClientActor: Executor updated: app-20140730162748-0026/0 is now RUNNING
14/07/30 16:34:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
14/07/30 16:34:06 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@brick3.ipads-lab.se.sjtu.edu.cn:52834/user/Executor#1717563428] with ID 0
14/07/30 16:34:06 INFO TaskSetManager: Re-computing pending task lists.
14/07/30 16:34:06 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor 0: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/07/30 16:34:06 INFO TaskSetManager: Serialized task 0.0:0 as 3522 bytes in 6 ms
14/07/30 16:34:06 INFO TaskSetManager: Starting task 0.0:1 as TID 1 on executor 0: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/07/30 16:34:06 INFO TaskSetManager: Serialized task 0.0:1 as 3522 bytes in 2 ms
14/07/30 16:34:06 INFO TaskSetManager: Starting task 0.0:2 as TID 2 on executor 0: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/07/30 16:34:06 INFO TaskSetManager: Serialized task 0.0:2 as 3522 bytes in 2 ms
14/07/30 16:34:06 INFO TaskSetManager: Starting task 0.0:3 as TID 3 on executor 0: brick3.ipads-lab.se.sjtu.edu.cn (PROCESS_LOCAL)
14/07/30 16:34:06 INFO TaskSetManager: Serialized task 0.0:3 as 3691 bytes in 3 ms
14/07/30 16:34:07 INFO BlockManagerInfo: Registering block manager brick3.ipads-lab.se.sjtu.edu.cn:44069 with 34.5 GB RAM
14/07/30 16:34:25 INFO TaskSchedulerImpl: Cancelling stage 0
14/07/30 16:34:25 INFO TaskSchedulerImpl: Stage 0 was cancelled
14/07/30 16:34:25 INFO DAGScheduler: Failed to run count at GraphLoader.scala:87
Exception in thread "main" org.apache.spark.SparkException: Job 0 cancelled because Stage 0 was cancelled
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1041)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1006)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply$mcVI$sp(DAGScheduler.scala:994)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:993)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:993)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:156)
	at org.apache.spark.scheduler.DAGScheduler.handleStageCancellation(DAGScheduler.scala:993)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1199)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)
	at akka.actor.ActorCell.invoke(ActorCell.scala:456)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)
	at akka.dispatch.Mailbox.run(Mailbox.scala:219)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
14/07/30 16:34:25 WARN TaskSetManager: Task 1 was killed.
14/07/30 16:34:25 WARN TaskSetManager: Task 3 was killed.
14/07/30 16:34:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
14/07/30 16:34:25 WARN TaskSetManager: Task 2 was killed.
14/07/30 16:34:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
14/07/30 16:34:25 WARN TaskSetManager: Task 0 was killed.
14/07/30 16:34:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
